{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Introduction to sounds with python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In this lesson we'll be discussing how to use python to process sounds. We will use python to read in sound files, generate sound files, manipulate sound files, and even play sound files. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Read in file as numpy array\n",
    "First, we'll try reading in a sound file. To do this we'll use the scipy package, and within scipy we'll be using a module called \"io\" (which stands for input/output). From this module, we are going to call a function that will read in a .wav file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.io.wavfile import read \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Now we have access to the read function. For example, if we call the help function, it will give us some information about what \"read\" can do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function read in module scipy.io.wavfile:\n",
      "\n",
      "read(filename, mmap=False)\n",
      "    Open a WAV file.\n",
      "    \n",
      "    Return the sample rate (in samples/sec) and data from an LPCM WAV file.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    filename : string or open file handle\n",
      "        Input WAV file.\n",
      "    mmap : bool, optional\n",
      "        Whether to read data as memory-mapped (default: False).  Not compatible\n",
      "        with some bit depths; see Notes.  Only to be used on real files.\n",
      "    \n",
      "        .. versionadded:: 0.12.0\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    rate : int\n",
      "        Sample rate of WAV file.\n",
      "    data : numpy array\n",
      "        Data read from WAV file. Data-type is determined from the file;\n",
      "        see Notes.  Data is 1-D for 1-channel WAV, or 2-D of shape\n",
      "        (Nsamples, Nchannels) otherwise. If a file-like input without a\n",
      "        C-like file descriptor (e.g., :class:`python:io.BytesIO`) is\n",
      "        passed, this will not be writeable.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    Common data types: [1]_\n",
      "    \n",
      "    =====================  ===========  ===========  =============\n",
      "         WAV format            Min          Max       NumPy dtype\n",
      "    =====================  ===========  ===========  =============\n",
      "    32-bit floating-point  -1.0         +1.0         float32\n",
      "    32-bit integer PCM     -2147483648  +2147483647  int32\n",
      "    24-bit integer PCM     -2147483648  +2147483392  int32\n",
      "    16-bit integer PCM     -32768       +32767       int16\n",
      "    8-bit integer PCM      0            255          uint8\n",
      "    =====================  ===========  ===========  =============\n",
      "    \n",
      "    WAV files can specify arbitrary bit depth, and this function supports\n",
      "    reading any integer PCM depth from 1 to 64 bits.  Data is returned in the\n",
      "    smallest compatible numpy int type, in left-justified format.  8-bit and\n",
      "    lower is unsigned, while 9-bit and higher is signed.\n",
      "    \n",
      "    For example, 24-bit data will be stored as int32, with the MSB of the\n",
      "    24-bit data stored at the MSB of the int32, and typically the least\n",
      "    significant byte is 0x00.  (However, if a file actually contains data past\n",
      "    its specified bit depth, those bits will be read and output, too. [2]_)\n",
      "    \n",
      "    This bit justification and sign matches WAV's native internal format, which\n",
      "    allows memory mapping of WAV files that use 1, 2, 4, or 8 bytes per sample\n",
      "    (so 24-bit files cannot be memory-mapped, but 32-bit can).\n",
      "    \n",
      "    IEEE float PCM in 32- or 64-bit format is supported, with or without mmap.\n",
      "    Values exceeding [-1, +1] are not clipped.\n",
      "    \n",
      "    Non-linear PCM (mu-law, A-law) is not supported.\n",
      "    \n",
      "    References\n",
      "    ----------\n",
      "    .. [1] IBM Corporation and Microsoft Corporation, \"Multimedia Programming\n",
      "       Interface and Data Specifications 1.0\", section \"Data Format of the\n",
      "       Samples\", August 1991\n",
      "       http://www.tactilemedia.com/info/MCI_Control_Info.html\n",
      "    .. [2] Adobe Systems Incorporated, \"Adobe Audition 3 User Guide\", section\n",
      "       \"Audio file formats: 24-bit Packed Int (type 1, 20-bit)\", 2007\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> from os.path import dirname, join as pjoin\n",
      "    >>> from scipy.io import wavfile\n",
      "    >>> import scipy.io\n",
      "    \n",
      "    Get the filename for an example .wav file from the tests/data directory.\n",
      "    \n",
      "    >>> data_dir = pjoin(dirname(scipy.io.__file__), 'tests', 'data')\n",
      "    >>> wav_fname = pjoin(data_dir, 'test-44100Hz-2ch-32bit-float-be.wav')\n",
      "    \n",
      "    Load the .wav file contents.\n",
      "    \n",
      "    >>> samplerate, data = wavfile.read(wav_fname)\n",
      "    >>> print(f\"number of channels = {data.shape[1]}\")\n",
      "    number of channels = 2\n",
      "    >>> length = data.shape[0] / samplerate\n",
      "    >>> print(f\"length = {length}s\")\n",
      "    length = 0.01s\n",
      "    \n",
      "    Plot the waveform.\n",
      "    \n",
      "    >>> import matplotlib.pyplot as plt\n",
      "    >>> import numpy as np\n",
      "    >>> time = np.linspace(0., length, data.shape[0])\n",
      "    >>> plt.plot(time, data[:, 0], label=\"Left channel\")\n",
      "    >>> plt.plot(time, data[:, 1], label=\"Right channel\")\n",
      "    >>> plt.legend()\n",
      "    >>> plt.xlabel(\"Time [s]\")\n",
      "    >>> plt.ylabel(\"Amplitude\")\n",
      "    >>> plt.show()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(read)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "Open a WAV file.\n",
      "\n",
      "Return the sample rate (in samples/sec) and data from an LPCM WAV file.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "filename : string or open file handle\n",
      "    Input WAV file.\n",
      "mmap : bool, optional\n",
      "    Whether to read data as memory-mapped (default: False).  Not compatible\n",
      "    with some bit depths; see Notes.  Only to be used on real files.\n",
      "\n",
      "    .. versionadded:: 0.12.0\n",
      "\n",
      "Returns\n",
      "-------\n",
      "rate : int\n",
      "    Sample rate of WAV file.\n",
      "data : numpy array\n",
      "    Data read from WAV file. Data-type is determined from the file;\n",
      "    see Notes.  Data is 1-D for 1-channel WAV, or 2-D of shape\n",
      "    (Nsamples, Nchannels) otherwise. If a file-like input without a\n",
      "    C-like file descriptor (e.g., :class:`python:io.BytesIO`) is\n",
      "    passed, this will not be writeable.\n",
      "\n",
      "Notes\n",
      "-----\n",
      "Common data types: [1]_\n",
      "\n",
      "=====================  ===========  ===========  =============\n",
      "     WAV format            Min          Max       NumPy dtype\n",
      "=====================  ===========  ===========  =============\n",
      "32-bit floating-point  -1.0         +1.0         float32\n",
      "32-bit integer PCM     -2147483648  +2147483647  int32\n",
      "24-bit integer PCM     -2147483648  +2147483392  int32\n",
      "16-bit integer PCM     -32768       +32767       int16\n",
      "8-bit integer PCM      0            255          uint8\n",
      "=====================  ===========  ===========  =============\n",
      "\n",
      "WAV files can specify arbitrary bit depth, and this function supports\n",
      "reading any integer PCM depth from 1 to 64 bits.  Data is returned in the\n",
      "smallest compatible numpy int type, in left-justified format.  8-bit and\n",
      "lower is unsigned, while 9-bit and higher is signed.\n",
      "\n",
      "For example, 24-bit data will be stored as int32, with the MSB of the\n",
      "24-bit data stored at the MSB of the int32, and typically the least\n",
      "significant byte is 0x00.  (However, if a file actually contains data past\n",
      "its specified bit depth, those bits will be read and output, too. [2]_)\n",
      "\n",
      "This bit justification and sign matches WAV's native internal format, which\n",
      "allows memory mapping of WAV files that use 1, 2, 4, or 8 bytes per sample\n",
      "(so 24-bit files cannot be memory-mapped, but 32-bit can).\n",
      "\n",
      "IEEE float PCM in 32- or 64-bit format is supported, with or without mmap.\n",
      "Values exceeding [-1, +1] are not clipped.\n",
      "\n",
      "Non-linear PCM (mu-law, A-law) is not supported.\n",
      "\n",
      "References\n",
      "----------\n",
      ".. [1] IBM Corporation and Microsoft Corporation, \"Multimedia Programming\n",
      "   Interface and Data Specifications 1.0\", section \"Data Format of the\n",
      "   Samples\", August 1991\n",
      "   http://www.tactilemedia.com/info/MCI_Control_Info.html\n",
      ".. [2] Adobe Systems Incorporated, \"Adobe Audition 3 User Guide\", section\n",
      "   \"Audio file formats: 24-bit Packed Int (type 1, 20-bit)\", 2007\n",
      "\n",
      "Examples\n",
      "--------\n",
      ">>> from os.path import dirname, join as pjoin\n",
      ">>> from scipy.io import wavfile\n",
      ">>> import scipy.io\n",
      "\n",
      "Get the filename for an example .wav file from the tests/data directory.\n",
      "\n",
      ">>> data_dir = pjoin(dirname(scipy.io.__file__), 'tests', 'data')\n",
      ">>> wav_fname = pjoin(data_dir, 'test-44100Hz-2ch-32bit-float-be.wav')\n",
      "\n",
      "Load the .wav file contents.\n",
      "\n",
      ">>> samplerate, data = wavfile.read(wav_fname)\n",
      ">>> print(f\"number of channels = {data.shape[1]}\")\n",
      "number of channels = 2\n",
      ">>> length = data.shape[0] / samplerate\n",
      ">>> print(f\"length = {length}s\")\n",
      "length = 0.01s\n",
      "\n",
      "Plot the waveform.\n",
      "\n",
      ">>> import matplotlib.pyplot as plt\n",
      ">>> import numpy as np\n",
      ">>> time = np.linspace(0., length, data.shape[0])\n",
      ">>> plt.plot(time, data[:, 0], label=\"Left channel\")\n",
      ">>> plt.plot(time, data[:, 1], label=\"Right channel\")\n",
      ">>> plt.legend()\n",
      ">>> plt.xlabel(\"Time [s]\")\n",
      ">>> plt.ylabel(\"Amplitude\")\n",
      ">>> plt.show()\n",
      "\u001b[0;31mFile:\u001b[0m      /opt/miniconda3/envs/AudioTechII/lib/python3.10/site-packages/scipy/io/wavfile.py\n",
      "\u001b[0;31mType:\u001b[0m      function"
     ]
    }
   ],
   "source": [
    "#or, better, because it will open a pop-up dialog and not clog your code:\n",
    "?read"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Here we can see from the parameters that we need to pass to the `read` function (as a minimum): a string that represents the filename. Notice that it outputs two things: a sample rate, and a numpy array representing the samples of the sounds.\n",
    "\n",
    "Note that the function will look in the same directory where your current notebook is stored for the file. If it isn't there, it will throw an error. Use the `..` notation to tell Jupyter to look upwards in the directory tree for the file or `../NameOfFolder` if the file is in a parallel folder. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We will call the read function on a file uploaded to the \"uploaded_audio\" directory (copy over from Canvas) called \"Flute-A4.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "(fs, x) = read(\"../audio/BobMarley_track1.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  2, -2, ...,  0, -1,  1], dtype=int16)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## A few basics\n",
    "Now we can ask some things about this file, for example, how long is the array? We do this by calling the \"size\" attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2879830"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "So there are 2879830 samples in the file. If we want to know how many seconds that is, we can divide by the sampling rate (96,000 samples per second):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.99822916666667"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size/fs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We will do more in a bit with numpy and indexing, but for now:\n",
    "\n",
    "You can index a range of values with square brackets, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  2, -2,  2, -3,  2,  0,  0,  1, -2,  3, -3,  3, -2,  1,  0, -1,\n",
       "        1, -1,  2, -1,  1,  0, -1,  1, -2,  2, -2,  3, -2,  3, -2,  1, -1,\n",
       "        0,  0,  0, -1,  1, -1,  2, -2,  1, -2,  1, -1,  2,  0,  2,  0,  0,\n",
       "        1,  0,  1, -1,  2,  0,  0,  2, -3,  2, -1, -2,  0, -4, -1, -4,  1,\n",
       "       -4,  4, -3,  3, -1,  3, -1,  3, -2,  2, -2,  2,  0,  0,  1,  0,  0,\n",
       "       -1,  0, -5,  3, -8,  3, -3,  1,  6, -2,  7, -2,  3, -2, -1],\n",
       "      dtype=int16)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Basic plotting\n",
    "We can also plot the sound wave to see what it looks like. We'll do that using a popular python plotting library called matplotlib, and we'll mostly be using the pyplot module. So next, we'll import the pyplot module from the library, and give it a shortcut (or alias). Then we'll call the plot function and ask it to plot our array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "However, currently coordinates in this plot have default x-values according to their order (or \"index\" value; i.e., 1st, 2nd, 3rd, etc.). What would make more sense is to plot the x-axis according to time. How could we do that?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We will need to explicitly pass an array of time values to the x-axis. \n",
    "We can use the `numpy` library, which is designed for working with arrays. \n",
    "Specifically, we will need to convert sample positions to positions in time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We're going to use the \"arange\" function. Let's see what it does:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This is a really useful function and we'll likely be using it a lot. It creates a numpy array that begins with the \"start\" value, ends (before) the \"stop\" value, and increments by the \"step\" value. Notice that the \"start\" and \"step\" arguments are optional and have default values of 0 and 1, respectively. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Notice also the line about incrementing by non-integer values; in this case it's better to use the function linspace instead of arange. You can play around with them and test it out.\n",
    "\n",
    "(You will also want to read about `np.linspace`, which is similar and we will also use a lot)\n",
    "\n",
    "What will be the result of this function?:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Our variable \"x\" is an array containing the amplitude values for every sample. Here we use `np.arange` to convert the array to essentially its index value (or position)--so far doing exactly what `pyplot` was doing by default. \n",
    "However, if we then divide each value by the sample rate, we will have an array representing each sample's position on a time axis beginning from zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Notice that this is a vector operation (it automatically applied the division to every item in the array). Now we have a series of time values that \"line up with\" our sample values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can now redo our plot but this time plot *t* with respect to *x*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We should really always add titles and label our axes, so let's do that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can also play our sound back and hear what it sounds like. We'll do this by using the `Audio` function from IPython. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Audio will accept many files types including mp3, but we'll only be working with wav files for now. Note that audio also accepts a numpy array. However, you should be *extremely* cautious before playing back any numpy arrays you have created. **Always play back at very low volume first!!!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "You can also pass `Audio()` a numpy array. However, you'll need to provide a sample rate as one of the arguments (or else the function doesn't know what to do)! It needs the sample rate to be able to interpret the array. Like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "AudioTechII",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
